# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#
# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.
# See kafka.server.KafkaConfig for additional details and defaults
#


############################# Server Basics #############################
# 配合 broker 的 id：对于每个 broker.id 来说，必须设置为唯一的整数，且从 0 开始（注意：每台机器的 id 不同）
broker.id=${id}

# 删除 topic 功能
delete.topic.enable=true


############################# Socket Server Settings #############################
# broker 的服务端口
# port =9092

# kafka Server 端启动端口：每个节点需要配置自己的参数，kafka 真正 bind 的地址
listeners=PLAINTEXT://0.0.0.0:9092

# 暴露给外部的 listeners，如果没有设置，会用 listeners
advertised.listeners=PLAINTEXT://:9092

# listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# borker 进行网络处理的线程数
num.network.threads=4

# borker 进行 I/O 处理的线程数
num.io.threads=8

# 发送缓冲区 buffer 大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能
socket.send.buffer.bytes=102400

# kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘
socket.receive.buffer.bytes=102400

# 向 kafka 请求消息或者向 kafka 发送消息的请请求的最大数，不能超过 java 的堆栈大小
socket.request.max.bytes=104857600


############################# Log Basics #############################
# 数据日志文件存储路径（用逗号分隔的目录列表），num.io.threads 要大于目录的个数，
log.dirs=${KAFKA_HOME}/data

# 默认的分区数，一个 topic 默认 1 个分区数
num.partitions=3

# 启停 kafka 时，恢复和清理日志的线程数量，默认1，启动总线程数 = 此值 * log.dirs 目录数
num.recovery.threads.per.data.dir=2


############################# Internal Topic Settings  #############################
# 每个 Topic 的 log 日志副本数
offsets.topic.replication.factor=3

transaction.state.log.replication.factor=3

# 最少的 ISR 应答数
transaction.state.log.min.isr=1


############################# Log Flush Policy #############################
# log 日志文件刷写到磁盘之前累积的消息数目：需要在 数据可靠性 与 性能 之间做必要的权衡，值大,将会导致每次 IO 阻塞，值过小，将会刷写次数较多
# log.flush.interval.messages=10000

# 刷写日志的时间间隔，如果消息量始终没有达到阀值，但是离上一次磁盘同步的时间间隔达到阀值，也将触发
# log.flush.interval.ms=1000


############################# Log Retention Policy #############################
# 默认消息的最大持久化时间，168 小时，7 天
log.retention.hours=168

# 每个分区的最大文件大小（默认 1GB）：超出限制的部分数据会被删除，一般不设置，-1 为没有大小限制
# log.retention.bytes=1073741824

# 日志分片文件最大值，因为 kafka 的消息是以追加的形式落地到文件，当超过这个值的时候，kafka 会新起一个文件
log.segment.bytes=1073741824

# 检查 log 失效时间间隔（单位：毫秒）：查看是否有过期的消息如果有，删除
log.retention.check.interval.ms=300000

# 日志清理策略选择有：delete 和 compact 主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic 创建时的指定参数覆盖
# log.cleanup.policy = delete

# 是否启用 log 压缩，一般不用启用，启用的话可以提高性能
# log.cleaner.enable=false


############################# Zookeeper #############################
# 配置连接 zookeeper 的集群地址（用逗号分隔的目录列表）
zookeeper.connect=${kafka_zookeeper_node}

# 连接 zookeeper 的超时时间（单位：ms）
zookeeper.connection.timeout.ms=18000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0
