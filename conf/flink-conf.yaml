# env.java.home: ${JAVA_HOME}


# ====================================================== 基础 配置 ====================================================== #
# JobManager 的 IP 地址
jobmanager.rpc.address: master

# JobManager 的端口号
jobmanager.rpc.port: 6123

# JobManager 将绑定到的主机
jobmanager.bind-host: 0.0.0.0

# JobManager JVM heap 内存大小
jobmanager.memory.process.size: 2048m

# askManager 将绑定到的主机
taskmanager.bind-host: 0.0.0.0

# 运行 TaskManager 的主机地址，JobManager 和其他 TaskManager 可以访问该主机地址，需要为每个任 TaskManager 单独配置
taskmanager.host: ${task_host}

# TaskManager JVM heap 内存大小
taskmanager.memory.process.size: 2560m

# 要排除 JVM 元空间和开销，请使用 total Flink内存大小，不建议同时设置 taskmanager.memory.process.size 和 taskmanager.memory.flink.size 内存
taskmanager.memory.flink.size: 2048m

# taskmanager.memory.jvm-overhead.max: 8192m

# 每个 TaskManager 提供的任务 Slots 数量，建议与 cpu 核数一致
taskmanager.numberOfTaskSlots: ${cpu_thread}

# 程序默认并行计算的个数
parallelism.default: 4

# 文件系统来源
fs.default-scheme: hdfs://${namenode_host_port}


# ===================================================== 高可用 配置 ===================================================== #
# 高可用性配置，可以选择 NONE 或者 zookeeper
# high-availability: zookeeper

# 文件系统路径，让 Flink 在高可用性设置中持久保存元数据
# high-availability.storageDir: hdfs://${namenode_host_port}/flink/ha/

# zookeeper 集群中仲裁者的机器 ip 和 port 端口号(host1:port,host2:port,host3:port,...)
# high-availability.zookeeper.quorum: ${zookeeper_hosts}

# 默认是 open，如果 zookeeper security 启用了该值会更改成 creator
# high-availability.zookeeper.client.acl: open

# ================================================== 容错和检查点 配置 ================================================== #
# execution.checkpointing.interval: 3min
# execution.checkpointing.externalized-checkpoint-retention: [DELETE_ON_CANCELLATION, RETAIN_ON_CANCELLATION]
# execution.checkpointing.max-concurrent-checkpoints: 1
# execution.checkpointing.min-pause: 0
# execution.checkpointing.mode: [EXACTLY_ONCE, AT_LEAST_ONCE]
# execution.checkpointing.timeout: 10min
# execution.checkpointing.tolerable-failed-checkpoints: 0
# execution.checkpointing.unaligned: false

# 用于存储和检查点状态（hashmap、rocksdb、class-name-of-factory）
state.backend: rocksdb

# 存储 检查点 的数据文件和元数据的默认目录
state.checkpoints.dir: hdfs://${namenode_host_port}/flink/check-point

# 存储 保存点 数的默认目录(可选)
state.savepoints.dir: hdfs://${namenode_host_port}/flink/save-point

# 用于启用/禁用增量 checkpoints 的标志
state.backend.incremental: true

# 故障转移策略：只重新启动可能受到任务失败影响的任务
jobmanager.execution.failover-strategy: region


# ===================================================== WEB UI 配置 ===================================================== #
# Web UI 运行时监视器端口
rest.port: 8083

# 基于 Web 的运行时监视器侦听的地址：master
rest.address: 0.0.0.0

# Web 访问端口
rest.bind-port: 8084

# WebUI 绑定地址
rest.bind-address: 0.0.0.0

# 是否从基于 Web 的 JobManager 启用作业提交
web.submit.enable: true

# 是否从在 Web 页面取消作业
web.cancel.enable: true

# 页面临时文件存储路径
web.tmpdir: ${FLINK_HOME}/data/web-tmp

# 从页面上传的 jar 存储路径
web.upload.dir: ${FLINK_HOME}/data


# ====================================================== 高级 配置 ====================================================== #
# 暂存的临时文件路径：多个目录用英文逗号分隔
io.tmp.dirs: ${FLINK_HOME}/data/execute-tmp

# 日志文件路径
env.log.dir: ${FLINK_HOME}/logs

# 是否应在 TaskManager 启动时预先分配 TaskManager 管理的内存
# taskmanager.memory.preallocate: false

# 类加载解析顺序，是先检查用户代码 jar（child-first）还是应用程序类路径（parent-first），默认设置指示首先从用户代码 jar 加载类
classloader.resolve-order: child-first

# 
classloader.check-leaked-classloader: false

# 用于网络缓冲区的 JVM 内存的分数：决定 TaskManager 可以同时拥有多少流数据交换通道以及通道缓冲的程度，taskmanager.network.memory.min 和 taskmanager.network.memory.max 可能会覆盖此分数 
taskmanager.memory.network.fraction: 0.1

# 网络缓冲区的 JVM 最小内存
taskmanager.memory.network.min: 512mb

# 网络缓冲区的 JVM 最大内存
taskmanager.memory.network.max: 2048mb

# Hadoop 的配置文件目录
# fs.hdfs.hadoop.conf: ${HADOOP_HOME}/etc/hadoop


# ==================================================== 集群安全 配置 ==================================================== #
# 指示是否从 Kerberos ticket 缓存中读取
# security.kerberos.login.use-ticket-cache: true

# 包含用户凭据的 Kerberos 密钥表文件的绝对路径
# security.kerberos.login.keytab: /path/to/kerberos/keytab

# 与 keytab 关联的 Kerberos 主体名称
# security.kerberos.login.principal: flink-user

#  以逗号分隔的登录上下文列表，用于提供 Kerberos 凭据（例如，`Client，KafkaClient`使用凭证进行 ZooKeeper 身份验证和 Kafka 身份验证）
# security.kerberos.login.contexts: Client,KafkaClient


# =============================================== Zookeeper 集群安全 配置 =============================================== #
# 覆盖以下配置以提供自定义 ZK 服务名称
# zookeeper.sasl.service-name: zookeeper

# # 该配置必须匹配 security.kerberos.login.contexts 中的列表（含有一个）
# zookeeper.sasl.login-context-name: Client


# =================================================== 历史服务器 配置 =================================================== #
# 通过 bin/historyserver.sh (start|stop) 命令启动和关闭 HistoryServer
# 将已完成的作业上传到的目录
jobmanager.archive.fs.dir: hdfs://${namenode_host_port}/flink/completed

# 基于 Web 的 HistoryServer 的地址
historyserver.web.address: 0.0.0.0

# 基于 Web 的 HistoryServer 的端口号
historyserver.web.port: 8082

# 以逗号分隔的目录列表，用于监视已完成的作业
historyserver.archive.fs.dir: hdfs://${namenode_host_port}/flink/history

# 刷新受监控目录的时间间隔（以毫秒为单位）
historyserver.archive.fs.refresh-interval: 10000


# ====================================================== 其它 配置 ====================================================== #
# restart-strategy.fixed-delay.attempts: 6
# restart-strategy.fixed-delay.delay: 30 s
