# ==================================================================================================================== #
# fe_custom.conf 中的配置项会覆盖 fe.conf 中相同的配置项，fe_custom.conf 文件的位置可以在 fe.conf 通过 custom_config_dir 配置项配置
#  
# 查看配置项： 
#              http://fe_host:fe_http_port/variable
#              ADMIN SHOW FRONTEND CONFIG [LIKE "pattern"];  
#                  Key：配置项名称、            Value：配置项值、                    Type：配置项类型、
#                  IsMutable：是否可以动态配置、MasterOnly： 是否仅适用于 Master FE、Comment： 配置项说明
# 设置配置项：
#              ADMIN SET FRONTEND CONFIG ("fe_config_name" = "fe_config_value");
# ==================================================================================================================== #
    
# ================================================= 元数据与集群管理 ================================================= #
# Doris 元数据将保存目录
meta_dir = ${DORIS_HOME}/fe/data/meta

# 元数据锁的 tryLock 超时配置（ms）
# catalog_try_lock_timeout_ms = 5000

# 如果设置为 true，FE 将在 BDBJE 调试模式下启动，在 Web 页面 System -> bdbje 可以查看相关信息，否则不可以查看
# enable_bdbje_debug_mode = false

# 非主 FE 到主 FE 主机之间的最大可接受时钟偏差：非主 FE 通过 BDBJE 建立到主 FE 的连接时，都会检查该值，如果时钟偏差大于此值，则放弃连接（s）
# max_bdbje_clock_delta_ms = 5000

# 如果为 true，FE 将重置 bdbje 复制组（即删除所有可选节点信息）并应该作为 Master 启动
# metadata_failure_recovery = false

# 尝试重新加入组时 bdbje 可以回滚的最大 txn 数
# txn_rollback_limit = 100

# Master FE 等待 Follower FE 发送 ack 的超时时间
# bdbje_replica_ack_timeout_second = 10

# 在 grpc_threadmgr 中处理 grpc events 的线程数量
# grpc_threadmgr_threads_nums = 4096

# bdbje 操作的 lock timeout 如果 FE WARN 日志中有很多 LockTimeoutException，可以尝试增加这个值
bdbje_lock_timeout_second = 5

# Master 和 Follower 之间 bdbje 的心跳超时（s）
# bdbje_heartbeat_timeout_second = 30

# bdbje 的副本 ack 策略（ALL, NONE, SIMPLE_MAJORITY）
# replica_ack_policy = SIMPLE_MAJORITY

# bdbje 的Follower FE 同步策略（SYNC, NO_SYNC, WRITE_NO_SYNC）
# replica_sync_policy = SYNC

# Master FE 的 bdbje 同步策略（SYNC, NO_SYNC, WRITE_NO_SYNC）：部署一个 FE，设置为 SYNC， 如果部署超过 3 个，设置为 WRITE_NO_SYNC
# master_sync_policy = SYNC

# 用于限制 bdbje 能够保留的文件的最大磁盘空间
# bdbje_reserved_disk_bytes = 1073741824

# 是否非主 FE 将忽略主 FE 与其自身之间的元数据延迟间隙，即使元数据延迟间隙超过 meta_delay_toleration_second，非主 FE 仍将提供读取服务
# ignore_meta_check = false

# 如果元数据延迟间隔超过配置，非主 FE 将停止提供服务（s）
# meta_delay_toleration_second = 300

# bdbje 编辑日志端口
edit_log_port = 9010

# 编辑日志类型：BDB，将日志写入 bdbje LOCAL，已弃用
# edit_log_type = BDB

# Master FE 保存镜像日志时间间隔
# edit_log_roll_num = 50000

# 如果设置为 true，则无论 jvm 内存使用百分比如何，检查点线程都会创建检查点
# force_do_metadata_checkpoint = false

# 如果 jvm 内存使用百分比（堆或旧内存池）超过此阈值，则检查点线程将无法工作以避免 OOM
# metadata_checkpoint_memory_threshold = 60

# 用于设置回收站中同名元数据的最大个数，超过最大值时，最早删除的元数据将被彻底删除，不能再恢复，0：不保留同名对象，< 0：表示不做限制
# max_same_name_catalog_trash_num = 3

# 如果节点（FE 或 BE）具有相同的集群 id，则属于同一个 Doris 集群，通常是主 FE 首次启动时生成的随机整数 也可以指定
# cluster_id = -1

# 在 heartbeat_mgr 中存储心跳任务的阻塞队列大小
# heartbeat_mgr_blocking_queue_size = 1024

# heartbeat_mgr 中处理心跳事件的线程数
# heartbeat_mgr_threads_num = 8

# 是否禁用与集群功能相关的所有操作，包括：创建/删除集群、添加、释放 BE、更改集群的后端数量、迁移数据库
# disable_cluster_feature = true

# 是否使用第三方部署管理器部署 Doris（disable：没有部署管理器、k8s：Kubernetes、ambari：Ambari、local：本地文件）
# enable_deploy_manager = disable

# 如果在本地使用 k8s 部署管理器，请将其设置为 true 并准备证书文件
# with_k8s_certs = false

# 用于 k8s 部署环境，当 enable_fqdn_mode 为 true 时，将允许更改 be 的重建 pod 的 ip
# enable_fqdn_mode =  false

# 为了向前兼容，稍后将被删除 下载 image 文件时检查令牌
# enable_token_check = true

# 是否开启单 BE 的多标签功能
# enable_multi_tags = false
    
# ======================================================= 服务 ======================================================= #
# FE 通过 mysql 协议查询连接端口
query_port = 9030

# 显式配置 FE 的 IP 地址，不使用 InetAddressgetByName 获取 IP 地址，只支持 IP 地址，不支持主机名（已弃用，不建议使用）
# frontend_address = 0.0.0.0

# 为有很多 ip 的服务器声明一个选择策略：最多应该有一个 ip 与此列表匹配 这是一个以分号分隔格式的列表
# priority_networks = 10.10.10.0/24
priority_networks = ${priority_networks}
                                                    
# FE http 端口，所有 FE http 端口都必须相同
http_port = 8030

# FE https 端口，所有 FE https 端口都必须相同
https_port = 8050

# FE https 使能标志位，false 表示支持 http，true 表示同时支持 http 与 https（需要配置 ssl 证书信息），会自动将 http 请求重定向到 https
# enable_https = false

# 是否开启 doris 将与 mysql服务 建立基于 SSL 协议的加密通道
# enable_ssl = true

# 每个 FE 的最大连接数
# qe_max_connection = 1024

# 查询请求调度器中的最大线程数：有请求过来，就为其单独申请一个线程进行服务
# max_connection_scheduler_threads_num = 4096

# Doris 将检查已编译和运行的 Java 版本是否兼容，如果不兼容将抛出 Java 版本不匹配的异常信息，并终止启动
# check_java_version = true

# FE Thrift Server 的端口
rpc_port = 9020

# FE 的 Thrift 服务使用的服务模型：SIMPLE，TSimpleServer 模型，仅限于测试使用；THREADED，TThreadedSelectorServer 模型，非阻塞式 I/O 模型，即主从 Reactor 模型、THREAD_POOL，TThreadPoolServer 模型，阻塞式 I/O 模型，使用线程池处理用户连接，并发连接数受限于线程池的数量
# thrift_server_type = THREAD_POOL

# Thrift Server 最大工作线程数
# thrift_server_max_worker_threads = 4096

# thrift 服务器的 backlog_num，应该确保值大于 linux /proc/sys/net/core/somaxconn 配置
# thrift_backlog_num = 1024

# thrift 服务器的连接超时和套接字超时配置：设置为零以防止读取超时
# thrift_client_timeout_ms = 0

# 是否使用压缩格式发送查询计划结构体：开启后，可以降低大小，但在高并发小查询场景下，可能会降低约 10% 的并发度
# use_compact_thrift_rpc = true

# 用于设置 GRPC 客户端通道的初始流窗口大小，也用于设置最大消息大小当结果集
# grpc_max_message_size_bytes = 1G

# mysql 中处理任务的最大线程数
# max_mysql_service_task_threads_num = 4096

# mysql 中处理 io 事件的线程数
# mysql_service_io_threads_num = 4

# mysql nio server 的 backlog_num，应该同时放大 linux /proc/sys/net/core/somaxconn 文件中的值
# mysql_nio_backlog_num = 1024

# Broker rpc 的默认超时时间（s）
# broker_timeout_ms = 10000

# FE 向 BE 的 BackendService 发送 rpc 请求时的超时时间
# backend_rpc_timeout_ms = 60000

# 控制系统在成功下线 BE 后，是否删除 BE：false，BE 成功下线后，会一直处于 DECOMMISSION 状态，但不会被删除
# drop_backend_after_decommission = false

# 如果 BE 关闭了 max_backend_down_time_second，将触发 BACKEND_DOWN 事件（s）
# max_backend_down_time_second = 3600

# 用于禁止 BE 黑名单功能：禁止后，向 BE 发送查询请求失败，不会将 BE 添加到黑名单，该参数适用于回归测试环境
# disable_backend_black_list = false

# 最大可容忍的 BE 节点心跳失败次数：连续心跳失败次数超过值，会将 BE 状态置为 dead
# max_backend_heartbeat_failure_tolerance_count = 1

# 此配置用于在通过代理访问 bos 或其他云存储时尝试跳过代理
# enable_access_file_without_broker = false

# 是否重新发送代理任务：调大该配置的值可以有效解决代理任务的重复发送问题，但同时会导致，提交失败或者执行失败的代理任务，再次被执行的时间延长
# agent_task_resend_wait_time_ms = 5000

# 代理任务线程池中处理代理任务的最大线程数
# max_agent_task_threads_num = 4096

# 异步执行远程 fragment 的超时时间（ms）
remote_fragment_exec_timeout_ms = 30000

# 用于内部身份验证的集群令牌
# auth_token = 

# HTTP Server V2 由 SpringBoot 实现，并采用前后端分离的架构只有启用 httpv2，用户才能使用新的前端 UI 界面
enable_http_server_v2 = true

# 基本路径是所有 API 路径的 URL 前缀：在 Config.http_api_extra_base_path 中配置的路径
# http_api_extra_base_path

# Jetty 的 acceptors 线程数量
# jetty_server_acceptors = 2

# Jetty 的 selectors 线程数量
# jetty_server_selectors = 4

# Jetty 的 workers 线程数量
# jetty_server_workers = 0

# put 或 post 方法上传文件的最大字节数：100 * 1024 * 1024
# jetty_server_max_http_post_size = 100MB

# http header size 配置参数
# jetty_server_max_http_header_size = 1048576 （1M）

# 是否开启链路追踪，启用此配置，还应该指定 trace_export_url
# enable_tracing = false

# 链路追踪：zipkin，直接将 trace 导出到 zipkin，用于快速开启 tracing 特；collector，用于接收和处理 traces，支持导出到多种第三方系统，还需要指定 enable_tracing = true 和 trace_export_url
# trace_exporter = zipkin

# trace 导出到 zipkin
# trace_export_url = http://127.0.0.1:9411/api/v2/spans

# trace 导出到 collector
# trace_export_url = http://127.0.0.1:4318/v1/traces

# ===================================================== 查询引擎 ===================================================== #
# 用来限制单个用户同一时刻可使用的查询 instance 个数该参数小于等于 0 表示无限制（max_query_instances 小于等于 0 时，使用该配置）
# default_max_query_instances = -1

# 查询重试次数
# max_query_retry_time = 1

# 用于限制创建动态分区表时可以创建的最大分区数
# max_dynamic_partition_num = 500

# 是否启用动态分区调度，默认启用
dynamic_partition_enable = true

# 检查动态分区的频率（s）
# dynamic_partition_check_interval_seconds = 600

# 用于限制批量创建分区表时可以创建的最大分区数，避免一次创建过多分区（1.2.0 以上）
# max_multi_partition_num = 4096


# 分区名前缀，仅 multi partition 生效，不作用于动态分区
# multi_partition_name_prefix = p_

# 更新内存中全局分区信息的时间（s）
# partition_in_memory_update_interval_secs = 300

# 是否启用并发更新
enable_concurrent_update = true

# 用于控制用户表表名大小写是否敏感：该配置只能在集群初始化时配置，初始化完成后集群重启和升级时不能修改（0：按指定存储，区分大小写；1：表名以小写存储，比较不区分大小写 2：表名按指定存储，但以小写形式进行比较）
lower_case_table_names = 1

# 用于控制最大的表名长度
# table_name_length_limit = 64

# 是否缓存查询结果集：适用于离线数据更新场景
# cache_enable_sql_mode = true

# 如果设置为 true，FE 将从 BE cache 中获取数据，该选项适用于部分分区的实时更新
# cache_enable_partition_mode = true

# 设置可以缓存的最大行数
# cache_result_max_row_count = 3000

# 设置可以缓存的最大数据大小（B）
# cache_result_max_data_size = 31457280

# 缓存结果时上一版本的最小间隔，该参数区分离线更新和实时更新
# cache_last_version_interval_second = 900

# 创建唯一表时是否添加删除标志列
# enable_batch_delete_by_default = false

# 用于限制 delete 语句中 Predicate 的元素个数
# max_allowed_in_element_num_of_delete = 1024

# 控制 Rollup 作业并发限制
# max_running_rollup_job_num_per_table = 1

# 限制哈希分布修剪器的最大递归深度
# max_distribution_pruner_recursion_depth = 100

# 设置为 true，Planner 将尝试在与此前端相同的主机上选择 tablet 的副本
# enable_local_replica_selection = false

# 与 enable_local_replica_selection 配合使用，当本地副本不可用时，使用非本地副本服务查询
# enable_local_replica_selection_fallback = false

# 限制 expr 树的深度 超过此限制可能会导致在持有 db read lock 时分析时间过长
# expr_depth_limit = 3000

# 限制 expr 树的 expr 子节点的数量：超过此限制可能会导致在持有数据库读锁时分析时间过长
# expr_children_limit = 10000

# 用于定义 fragment 之间传递 block 的序列化格式
# be_exec_version = 

# 目前支持的最新数据版本，不可修改，应与 BeExecVersionManager::max_be_exec_version 一致
# max_be_exec_version = 

# 目前支持的最旧数据版本，不可修改，应与配套版本的的 BeExecVersionManager::min_be_exec_version 一致
# min_be_exec_version

# 用于设置保存查询的 profile 的最大个数
# max_query_profile_num = 100

# 两个发布版本操作之间的最小间隔（ms）
# publish_version_interval_ms = 10

# 一个事务的所有发布版本任务完成的最大等待时间（s）
# publish_version_timeout_second = 30

# colocate join PlanFragment instance 的 memory_limit = exec_mem_limit / min (query_colocate_join_memory_limit_penalty_factor, instance_num)
# query_colocate_join_memory_limit_penalty_factor = 1

# 重写聚合类型，session 级别生效，对于 AGG 模型生效
# rewrite_count_distinct_to_bitmap_hll = true
    
# ==================================================== 导入与导出 ==================================================== #
# 是否开启向量化导入
# enable_vectorized_load = true

# 是否开启新的 file scan node
# enable_new_load_scan_node = true

# 可过滤数据（由于数据不规则等原因）的最大百分比：0 表示严格模式，只要数据有一条被过滤掉整个导入失败
# default_max_filter_ratio = 0

# 控制同一个 DB 的并发导入个数的：当集群中有过多的导入任务正在运行时，新提交的导入任务可能会报错
# max_running_txn_num_per_db = 1000

# 设置为 true，处理错误的 insert stmt 仍将返回一个标签，可以使用此标签来检查导入作业的状态
# using_old_load_usage_pattern = false

# 如果这设置为 true：调用开始 txn api 时，所有挂起的导入作业都将失败；调用 commit txn api 时，所有准备导入作业都将失败；所有提交的导入作业将等待发布
# disable_load_job = false

# 在提交一个事务之前插入所有数据的最大等待时间（s）
# commit_timeout_second = 30

# 最大加载任务数，包括 PENDING、ETL、LOADING、QUORUM_FINISHED 如果超过此数量，则不允许提交导入作业
# max_unfinished_load_job = 1000

# 一个主守护线程将每 db_used_data_quota_update_interval_secs 更新数据库 txn 管理器的数据库使用数据配额
# db_used_data_quota_update_interval_secs = 300 (s)

# 是否禁用显示 stream load 并清除内存中的 stream load 记录
# disable_show_stream_load = false

# 可以存储在内存中的最近 stream load 记录的默认最大数量
# max_stream_load_record_size = 5000

# 获取 stream load 记录间隔
# fetch_stream_load_record_interval_second = 120

# broker scanner 程序可以在一个 broker 加载作业中处理的最大字节数：通常，每个 BE 都有一个 broker scanner 程序（500G）
# max_bytes_per_broker_scanner = 500 1024 1024 * 1024L

# 单个节点 broker load 导入的默认并发度：与 max_broker_concurrency、min_bytes_per_broker_scanner 等多个配置共同决定导入任务的并发度
# default_load_parallelism = 1

# broker scanner 的最大并发数
# max_broker_concurrency = 10

# 单个 broker scanner 将读取的最小字节数(64M)
# min_bytes_per_broker_scanner = 67108864L

# 自动恢复 Routine load 的周期（s）
# period_of_auto_resume_min = 5

# 只要有一个 BE 宕机，Routine Load 就无法自动恢复
# max_tolerable_backend_down_num = 0

# 每个 BE 的最大并发例 Routine Load 任务数：应小于 routine_load_thread_pool_size（10），这是 BE 上的 Routine Load 任务线程池大小
# max_routine_load_task_num_per_be = 5

# 单个 Routine Load 作业的最大并发任务数
# max_routine_load_task_concurrent_num = 5

# 最大 Routine Load 作业数，包括 NEED_SCHEDULED, RUNNING, PAUSE
# max_routine_load_job_num = 100

# routine load V2 版本加载的默认等待作业数
# desired_max_waiting_jobs = 100

# 默认不禁用，将来不推荐使用 hadoop 集群 load 设置为 true 以禁用这种 load 方式
# disable_hadoop_load = false

# 是否临时启用 spark load：1.2.* 中已经删除，默认开启 spark_load
# enable_spark_load = false

# Spark 负载调度程序运行间隔（s）
# spark_load_checker_interval_second = 60

# loading_load 任务执行程序池大小：当前，仅限制 broker load 的 loading_load 任务的数量
# async_loading_load_task_pool_size = 10

# pending_load 任务执行程序池大小：当前，仅限制 broker load 和 spark load 的 pending_load 任务的数量
# async_pending_load_task_pool_size = 10

# 是否启动单副本数据导入功能
# enable_single_replica_load = false

# 最小超时时间，适用于所有类型的 load（s）
# min_load_timeout_second = 1

# stream load 和 mini load 最大超时时间（s）
# max_stream_load_timeout_second = 259200

# load 最大超时时间，适用于除 stream load 之外的所有类型的加载（s）
# max_load_timeout_second = 259200

# 默认 stream load 和 mini load 超时时间（s）
# stream_load_default_timeout_second = 86400 * 3

# 默认 stream load 预提交超时时间（s）
# stream_load_default_precommit_timeout_second = 3600

# 默认 insert load 超时时间（s）
# insert_load_default_timeout_second = 3600

# 默认非 stream load 类型的 mini load 的超时时间（s）
# mini_load_default_timeout_second = 3600（1小时）

# Broker load 的默认超时时间（s）
# broker_load_default_timeout_second = 14400

# 默认 Spark 导入超时时间（s）
# spark_load_default_timeout_second = 86400

# Hadoop 导入超时时间（s）
# hadoop_load_default_timeout_second = 86400 * 3

# Load 任务数量限制，无限制
# load_running_job_num_limit = 0

# Load 作业输入的数据大小，无限制
# load_input_size_limit_gb = 0

# NORMAL 优先级 etl 加载作业的并发数
# load_etl_thread_num_normal_priority = 10

# 高优先级 etl 加载作业的并发数
# load_etl_thread_num_high_priority = 3

# NORMAL 优先级挂起加载作业的并发数
# load_pending_thread_num_normal_priority = 10

# 高优先级挂起加载作业的并发数：HIGH，小批量加载作业；NORMAL，其他类型的加载作业
# load_pending_thread_num_high_priority = 3

# 负载调度器运行间隔（s）
# load_checker_interval_second = 5

# 负载中落后节点的最大等待时间，这也用于等待发布任务时（s）
# load_straggler_wait_second = 300

# 多长时间将删除已完成或取消的加载作业的标签：去除的标签可以重复使用，设置较短的时间会降低 FE 内存使用量
# label_keep_max_second = 3 24 3600

# 对于一些高频负载工作，如果时间过期，则删除已完成的作业或任务（s）
# streaming_label_keep_max_second = 43200

# load 标签清理器，运行一次以清理过时作业的时间（s）
# label_clean_interval_second = 3600
    
# visible、aborted 状态事务被清除的时间间隔
# transaction_clean_interval_second = 30

# 提交事务的最大时间间隔：若超过了这个时间 channel 中还有数据没有提交，consumer 会通知 channel 提交事务
# sync_commit_interval_second = 10

# 数据同步作业运行状态检查间隔（s）
# sync_checker_interval_second = 10

# 数据同步作业线程池中的最大线程数量
# max_sync_task_threads_num = 10

# 提交事务需满足的最小 event 数量
# min_sync_commit_size = 10000

# 提交事务需满足的最小数据大小（15M）
# min_bytes_sync_commit = 15 * 1024 * 1024

# 数据同步作业线程池中的最大线程数量：整个 FE中 只有一个，用于处理 FE 中所有数据同步作业向 BE 发送数据的任务
# max_bytes_sync_commit = 10

# 是否允许 outfile 函数将结果导出到本地磁盘
# enable_outfile_to_local = false

# 每个导出查询计划的 tablet 数量
# export_tablet_num_per_task = 5

# 导出作业的默认超时时间（s）
# export_task_default_timeout_second = 2 * 3600

# 运行导出作业的并发限制：0，表示无限制
# export_running_job_num_limit = 5

# 导出检查器的运行间隔
# export_checker_interval_second = 5
    
# ======================================================= 日志 ======================================================= #
# 一个系统日志和审计日志的最大大小（MB）
log_roll_size_mb = 1024

# FE 日志目录：fe.log，FE进程的所有日志；fe.warn.log，FE 进程的所有警告和错误日志
sys_log_dir = ${DORIS_HOME}/fe/log

# 日志级别：INFO, WARNING, ERROR, FATAL
sys_log_level = INFO

# 要保存在 sys_log_roll_interval 内的最大 FE 日志文件：表示一天最多有 10 个日志文件
sys_log_roll_num = 10

# log4j DEBUG 级别实现：sys_log_verbose_modules = org.apache.doris.catalog 只会打印包 org.apache.doris.catalog 及其所有子包中文件的调试日志
# sys_log_verbose_modules = {}

# DAY，前缀是 yyyyMMdd；HOUR，前缀是 yyyyMMddHH
# sys_log_roll_interval = DAY

# 日志保存时长（d，天；h，小时；m，分钟；s，秒）
# sys_log_delete_age = 7d

# 日志拆分的大小
# sys_log_roll_mode = SIZE-MB-1024

# 审计日志目录：fe.audit.log，包含所有请求以及相关信息
audit_log_dir = ${DORIS_HOME}/fe/log

# 保留在 audit_log_roll_interval 内的最大 FE 审计日志文件
# audit_log_roll_num = 90

# 慢查询包含所有开销超过 qe_slow_log_ms 的查询
# audit_log_modules = {"slow_query", "query", "load", "stream_load"}

# 如果查询的响应时间超过此阈值，则会在审计日志中记录为 slow_query（ms）
# qe_slow_log_ms = 5000

# DAY，前缀是 yyyyMMdd；HOUR，前缀是 yyyyMMddHH
# audit_log_roll_interval = DAY

# 审计日志保留时间（d，天；h，小时；m，分钟；s，秒）
# audit_log_delete
    
# ======================================================= 存储 ======================================================= #
# 用于设置单个分片的最小副本数量
# min_replication_num_per_tablet = 1

# 用于设置单个分片的最大副本数量
# max_replication_num_per_tablet = 32767

# 默认数据库数据配额大小，设置单个数据库的配额大小可以使用（B/K/KB/M/MB/G/GB/T/TB/P/PB，ALTER DATABASE db_name SET DATA QUOTA quota;）
# default_db_data_quota_bytes = 1PB

# 默认数据库副本数量配额大小，设置单个数据库配额大小可以使用（ALTER DATABASE db_name SET REPLICA QUOTA quota;）
# default_db_replica_quota_size = 1073741824

# 设置为 true 系统会将损坏的 分片 替换为空 tablet，以确保查询可以执行 （但此时数据已经丢失，所以查询结果可能不准确）
# recover_with_empty_tablet = false

# disable：出现异常会正常报错，ignore_version：忽略 fe 分区中记录的 visibleVersion 信息，使用副本版本，ignore_all：除了 ignore_version，在遇到找不到可查询的副本时，直接跳过而不是抛出异常
# recover_with_skip_missing_version = disable

# 用于限制克隆任务的最小超时间（s）
# min_clone_task_timeout_sec = 180

# 用于限制克隆任务的最小和最大超时间（s）
# max_clone_task_timeout_sec = 7200

# 设置为 true， ReportHandler 将不会检查分片的存储介质， 并使得存储冷却功能失效
# disable_storage_medium_check = false

# 用于控制 FE 是否执行检测（Decommission）BE 上分片状态的阈值
# decommission_tablet_check_threshold = 5000

# 仅在使用 PartitionRebalancer 时有效
# partition_rebalance_max_moves_num_per_selection = 10

# 仅在使用 PartitionRebalancer 时有效，如果更改，缓存移动清除的时长（s）
# partition_rebalance_move_expire_after_access = 600

# 平衡器类型：BeLoad、Partition
# tablet_rebalancer_type = BeLoad

# 分片调度器中的 平衡分片 数量超过值时，则不再进行平衡检查
# max_balancing_tablets = 100

# 分片调度器中调度的 分片 数量超过值时，则跳过检查
# max_scheduling_tablets = 2000

# 如果设置为 true，分片调度器将不会做均衡
# disable_balance = false

# 如果设置为 true，分片调度器 将不会做单个 BE 上磁盘之间的 均衡
# disable_disk_balance = true

# 集群均衡百分比的阈值，如果一个 BE 的负载分数比平均分数低 10%，这个后端将被标记为低负载，如果负载分数比平均分数高 10%，将被标记为高负载
# balance_load_score_threshold = 0.1 (10%)

# 磁盘容量的高水位使用百分比（75%）
# capacity_used_percent_high_water = 0.75

# BE 副本数的平衡阈值
# clone_distribution_balance_threshold = 0.2

# BE 中数据大小的平衡阈值
# clone_capacity_balance_threshold = 0.2

# 设置为 true 以禁用自动 colocate 表的重新定位和平衡，ColocateTableBalancer 将不会重新定位和平衡并置表
# disable_colocate_balance = false

# 均衡时每个路径的默认 slot 数量
# balance_slot_num_per_path = 1

# 设置为 true，将关闭副本修复和均衡逻辑
# disable_tablet_scheduler = false

# 设置为 true，系统会在副本调度逻辑中，立即删除冗余副本
# enable_force_drop_redundant_replica = false

# 重分布一个 Colocation Group 可能涉及大量的分片迁移时间（s）
# colocate_group_relocate_delay_second = 1800

# 是否允许同一个分片的多个副本分布在同一个节点上
# allow_replica_on_same_host = false

# 设置为 true，会自动检测 压缩 比较慢的副本，并将迁移到其他机器
# repair_slow_replica = false

# 版本计数阈值，用来判断副本做 压缩 的速度是否太慢
# min_version_count_indicate_replica_compaction_too_slow = 200

# 设置为 true，则在选择可查询副本时，将跳过 压缩 较慢的副本
# skip_compaction_slower_replica = true

# 最慢副本的版本计数与最快副本的差异有效比率阈值
# valid_version_count_delta_ratio_between_replicas = 0.5

# 数据大小阈值，用来判断副本的数据量是否太大(2G)
# min_bytes_indicate_replica_too_large = 2 * 1024 * 1024 * 1024

# 分片调度程序中每个路径的默认 slot 数量
# schedule_slot_num_per_path = 2

# 决定修复 分片 前的延迟时间因素（s）
# tablet_repair_delay_factor_second = 60

# 存储容量使用率百分比（95%）
# storage_flood_stage_usage_percent = 95

# 存储容量剩余容量字节（B）
# storage_flood_stage_left_capacity_bytes =  1 1024 1024 * 1024

# 限制 BE 端存储路径使用最大容量百的分比
# storage_high_watermark_usage_percent = 85 (85%)

# 限制 BE 端存储路径的最小剩余容量
# storage_min_left_capacity_bytes =  2 * 1024 * 1024 * 1024 (2GB)

# 删除数据库（表/分区）后的最大数据保留时间（s）
# catalog_trash_expire_second = 86400L

# 指定分片在 SSD 上停留的默认时间 之后，将自动移动到 HDD（30天）
# storage_cooldown_second = 30 * 24 * 3600L 

# 默认存储介质（HDD、SSD）
# default_storage_medium = HDD

# 是否开启 存储策略 功能，该功能用户冷热数据分离功能
# enable_storage_policy = false即不开启

# 单个一致性检查任务的默认超时（s）
# check_consistency_default_timeout_second = 600

# 一致性检查开始时间
# consistency_check_start_time = 23

# 一致性检查结束时间
# consistency_check_end_time = 23

# 副本之间的最小延迟秒数失败，并且尝试使用克隆来恢复它
# replica_delay_recovery_second = 0

# 创建单个副本的最长等待时间（s）
# tablet_create_timeout_second = 1

# 删除单个副本的最长等待时间（s）
# tablet_delete_timeout_second = 2

# 修改表请求的最大超时时间（s）
# alter_table_timeout_second = 86400 * 30 

# OLAP 表在做 schema 变更时，允许的最大副本数，副本数过大会导致 FE OOM
# max_replica_count_when_schema_change = 100000

# 作业的最大保留时间（s）
# history_job_keep_max_second = 7 * 24 * 3600

# 为了在创建表（索引）不等待太久，设置一个最大超时时间（s）
# max_create_table_timeout_second = 1 * 3600
    
# ====================================================== 外部表 ====================================================== #
# 多个 catalog 并发文件扫描线程数
# file_scan_node_split_num = 128

# 多个 catalog 并发文件扫描大小
# file_scan_node_split_size = 256 1024 1024

# FE 创建 iceberg 表的时间间隔（s）
# iceberg_table_creation_interval_second = 10

# 设置为 true，iceberg 表和 Doris 表的列定义必须一致；否则，Doris 只创建支持的数据类型的列
# iceberg_table_creation_strict_mode = true

# 内存中可以存储的最近 iceberg 库表创建记录的默认最大数量
# max_iceberg_table_creation_record_size = 2000

# hive 分区的最大缓存数量
# max_hive_partition_cache_num = 100000

# hive metastore 的默认超时时间
# hive_metastore_client_timeout_second = 10

# 用于 外部表的 元数据 缓存加载线程池的最大线程数
# max_external_cache_loader_thread_pool_size = 10

# 用于 外部表 的最大文件缓存数量
# max_external_file_cache_num = 100000

# 用于 外部表 的最大 schema 缓存数量
# max_external_schema_cache_num = 10000

# 设置缓存中的数据，在最后一次访问后多久失效（min）
# external_cache_expire_time_minutes_after_access = 1440

# FE 调用 ES API 获取索引分片信息的时间间隔（s）
# es_state_sync_interval_second = 10
    
# ===================================================== 外部资源 ===================================================== #
# dpp_hadoop_client_path = /lib/hadoop-client/hadoop/bin/hadoop

# dpp_bytes_per_reduce = 100 1024 1024L (100M)

# dpp_default_cluster = palo-dpp

# dpp_default_config_str = { hadoop_configs : 'mapred.job.priority=NORMAL;mapred.job.map.capacity=50;mapred.job.reduce.capacity=50;mapred.hce.replace.streaming=false;abaci.long.stored.job=true;dce.shuffle.enable=false;dfs.client.authserver.force_stop=true;dfs.client.auth.method=0' }

# dpp_config_str = { palo-dpp : { hadoop_palo_path : '/dir', hadoop_configs : 'fs.default.name=hdfs://host:port;mapred.job.tracker=host:port;hadoop.job.ugi=user,password' } }

# 默认的 Yarn 配置文件目录每次运行 Yarn 命令之前，需要检查一下这个路径下是否存在 config 文件，如果不存在，则创建它们
# yarn_config_dir = ${DORIS_HOME}/fe/lib/yarn-config

# 默认 Yarn 客户端路径
# yarn_client_path = ${DORIS_HOME}/fe/lib/yarn-client/hadoop/bin/yarn

# 指定的 Spark 启动器日志目录
# spark_launcher_log_dir =  ${DORIS_HOME}/fe/log/spark_launcher_log

# 默认值的 Spark 依赖路径
# spark_resource_path = 

# 默认的 Spark Home 路径
# spark_home_default_dir = ${DORIS_HOME}/fe/lib/spark2x

# Spark 默认版本号
# spark_dpp_version = 1.0.0
    
# ===================================================== 其它参数 ===================================================== #
# 临时文件保存目录
# tmp_dir = ${DORIS_HOME}/fe/temp_dir

# 自定义配置文件目录：配置 fe_custom.conf 文件的位置默认为 conf/ 目录下
# custom_config_dir = ${DORIS_HOME}/fe/conf

# 插件安装目录
# plugin_dir = ${DORIS_HOME}/plugins

# 插件是否启用
# plugin_enable = true

# 保存小文件的目录
# small_file_dir = ${DORIS_HOME}/small_files

# 小文件管理器 中单个文件存储的最大大小
# max_small_file_size_bytes = 1M

# 小文件管理器 中存储的最大文件数
# max_small_file_number = 100

# 设置为 true，指标收集器将作为守护程序计时器运行，以固定间隔收集指标
# enable_metric_calculator = true

# 为了避免在 FE 中堆积过多的报告任务，可能会导致 OOM 异常等问题，不建议修改这个值
# report_queue_size =  100

# 备份作业的默认超时时间（ms）
# backup_job_default_timeout_ms = 86400 * 1000

# 此配置用于控制每个 DB 能够记录的 backup/restore 任务的数量
# max_backup_restore_job_num_per_db = 10

# 是否开启 千分位 数据类型
# enable_quantile_state_type = false

# 设置为 true，FE 会自动将 Date/Datetime 转换为 DateV2/DatetimeV2(0)
# enable_date_conversion = false

# 如果设置为 true，FE 将自动将 DecimalV2 转换为 DecimalV3
# enable_decimal_conversion = false

# proxy_auth_magic_prefix = x@8

# proxy_auth_enable = false

# 在 ODBC、JDBC 的 Mysql 外部表查询时，是否将带函数的过滤条件下推到 Mysql 中执行
# enable_func_pushdown = true

# 用于存放默认的 jdbc 驱动目录
# jdbc_drivers_dir = ${DORIS_HOME}/jdbc_drivers;

# broker load job 保存的失败 分片 信息的最大数量
# max_error_tablet_of_broker_load = 3;

# 用于设置默认数据库事务配额大小
# default_db_max_running_txn_num = -1

# 设置为 true，对外部表的查询将优先分配给计算节点
# prefer_compute_node_for_external_table = false

# 仅在 prefer_compute_node_for_external_table 为 true 时生效，如果计算节点数小于此值，则对外部表的查询将尝试使用一些混合节点
# min_backend_num_for_external_table = 3

# 设置为 false 时，查询 information_schema 中的表时，将不再返回 external catalog 中的表的信息
# infodb_support_ext_catalog = false

# 控制是否启用查询命中率统计
# enable_query_hit_stats = false

# 此变量表示增加与/运算符执行的除法操作结果规模的位数
# div_precision_increment = 4

# ==================================================== 自定义参数 ==================================================== #
# LOG_DIR = ${DORIS_HOME}/fe/log

DATE = `date +%Y%m%d-%H%M%S`
JAVA_OPTS="-Xmx4096m -XX:+UseMembar -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=7 -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSClassUnloadingEnabled -XX:-CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=80 -XX:SoftRefLRUPolicyMSPerMB=0 -Xloggc:$DORIS_HOME/log/fe.gc.log.$DATE"

# For jdk 9+, this JAVA_OPTS will be used as default JVM options
JAVA_OPTS_FOR_JDK_9="-Xmx4096m -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=7 -XX:+CMSClassUnloadingEnabled -XX:-CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=80 -XX:SoftRefLRUPolicyMSPerMB=0 -Xlog:gc*:$DORIS_HOME/log/fe.gc.log.$DATE:time"

mysql_service_nio_enabled = true
    
# max_conn_per_user = 100
# qe_query_timeout_second = 300
