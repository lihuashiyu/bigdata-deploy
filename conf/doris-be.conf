# ==================================================================================================================== #
# be_custom.conf：用于记录用户在运行时动态配置并持久化的配置项，be_custom.conf 中的配置项会覆盖 be.conf 中相同的配置项
# 
# 查看配置项：http://be_host:be_webserver_port/varz
# 
# 设置配置项：curl -X POST http://{be_ip}:{be_http_port}/api/update_config?{key}={value}\&persist=true
#                 修改后的配置项存储在 be_custom.conf 文件中
# ==================================================================================================================== #

# ======================================================= 服务 ======================================================= #
# BE 上 thrift server 的端口号，用于接收来自 FE 的请求
be_port = 9060

# BE 上心跳服务端口（thrift），用于接收来自 FE 的心跳
heartbeat_service_port = 9050

# BE 上的 http server 的服务端口
webserver_port = 8040

# BE 上的 brpc 的端口，用于 BE 之间通讯
brpc_port = 8060

# 是否支持 https：如果为 true，需要配置 ssl_certificate_path 和 ssl_private_key_path
# enable_https = false

# 为有很多 ip 的服务器声明一个选择策略：最多应该有一个 ip 与此列表匹配，以分号分隔，用 CIDR 表示法，如果没有匹配到，会随机选择一个
# priority_networks = 10.10.10.0/24
# priority_networks = ${priority_networks}

# BE 数据存储的目录：多目录之间用的分号分隔，可以添加容量限制在每个路径的末尾，通过英文状态逗号隔开
# storage_root_path = /home/disk1/doris.HDD;/home/disk2/doris.SSD;/home/disk2/doris
# storage_root_path = ${DORIS_HOME}/be/data

# 执行BE上心跳服务的线程数，不建议修改
# heartbeat_service_thread_count = 1

# BE 启动时，是否会检查 storage_root_path 配置下的所有路径：如果为 false，路径不存在或路径下无法进行读写文件(坏盘)，将中断启动失败退出
# ignore_broken_disk=false

# 限制 BE 进程使用服务器最大内存百分比：用于防止 BE 内存挤占太多的机器内存，该参数必须大于 0，当百分大于 100% 之后，该值会默认为 100%
# mem_limit = 80%

# 配置 BE 的所属于的集群 id，该值通常由 FE 通过心跳向 BE 下发，不需要额外进行配置
# cluster_id = -1

# 配置 be_custom.conf 文件的位置
# custom_config_dir = 

# 回收站清理的间隔，72个小时，当磁盘空间不足时，回收站下的文件保存期可不遵守这个参数（s）
# trash_file_expire_time_sec = 259200

# 通过 http 连接 ES 的超时时间（ms）
# es_http_timeout_ms = 5000

# es_scroll_keepalive = 5
# es scroll Keeplive保持时间（min）

# 和外部表建立连接的超时时间（s）
# external_table_connect_timeout_sec = 5

# 配置文件报告之间的间隔（s）
# status_report_interval = 5

# brpc 包的最大值
# brpc_max_body_size = 

# 连接上有最大的未发送数据
# brpc_socket_max_unwritten_bytes

# 是否在 Tuple/Block data 长度大于 1.8G 时，将 protoBuf request 序列化后和 Tuple/Block data 一起嵌入到 controller attachment 
# transfer_large_data_by_brpc = true

# brpc 中线程的数量，-1，意味着线程数量为机器的 cpu 核数
# brpc_num_threads = -1

# thrift 超时时间（ms）
# thrift_rpc_timeout_ms = 60000

# be 的 thrift 客户端设置重试间隔，避免 fe 的 thrift server 发生雪崩问题（ms）
# thrift_client_retry_interval_ms = 1000

# thrift 客户端连接超时时间（s）
# thrift_connect_timeout_seconds = 3

# FE 的 Thrift服 务使用的服务模型，需要和 fe 的 thrift_server_type 参数的设置保持一致：THREADED，该模型为非阻塞式 I/O 模型；THREAD_POOL，该模型为阻塞式 I/O 模型
# thrift_server_type_of_fe = THREAD_POOL

# txn 提交 rpc 超时间隔（ms）
# txn_commit_rpc_timeout_ms = 60000

# txn_map_lock 分片大小，取值为 2^n，n = 0,1,2,3,4，可提高管理 txn 的性能
# txn_map_shard_size = 128、

# txn_lock 分片大小，取值为 2^n，n = 0,1,2,3,4，可提高提交和发布 txn 的性能
# txn_shard_size = 1024

# 清理过期 Rowset 的时间间隔（s）
# unused_rowset_monitor_interval = 30

# 每个主机的最大客户端缓存数，BE 中有多种客户端缓存，目前使用相同的缓存大小配置， 可使用不同的配置来设置不同的客户端缓存
# max_client_cache_size_per_host = 10

# String 类型最大长度的软限（B）
# string_type_length_soft_limit_bytes = 1048576

# 使用 odbc 外表时，如果 odbc 源表的某一列类型为 HLL，CHAR 或者 VARCHAR，并且列值长度超过该值，则查询报错
# big_column_size_buffer = 65535

# 使用 odbc 外表时，如果 odbc 源表的某一列类型不是 HLL，CHAR 或者 VARCHAR，并且列值长度超过该值，则查询报错
# small_column_size_buffer = 100

# json 类型最大长度的软限（B）
# jsonb_type_length_soft_limit_bytes = 1048576
    
# ======================================================= 查询 ======================================================= #
# 单节点上能够处理的查询请求上限
# fragment_pool_queue_size = 4096

# 查询线程数
# fragment_pool_thread_num_min = 64

# 后续查询请求动态创建线程
# fragment_pool_thread_num_max = 2048

# HashJoin 时，当 OlapScanner 扫描的数据大于 32768 行时，BE 会进行过滤条件检查，如果过滤率低于该配置，则 Doris 会停止使用动态分区裁剪的条件进行数据过滤
# doris_max_pushdown_conjuncts_return_rate = 90
#  

# 用于限制一个查询请求中，scan node 节点能拆分的最大 scan key 的个数
# doris_max_scan_key_num = 48

# 单个 OlapScanner 占用 io 线程的时间
# doris_scan_range_row_count = 524288

# 转换器线程 与 OlapScanner 之间 RowBatch 的缓存队列的长度
# doris_scanner_queue_size = 1024


# 每个扫描线程单次执行最多返回的数据行数
# doris_scanner_row_num = 16384

# 每个扫描线程单次执行最多返回的数据字节
# doris_scanner_row_bytes = 10485760

# 扫描器线程池的队列长度
# doris_scanner_thread_pool_queue_size = 102400

# 扫描器线程池线程数目
# doris_scanner_thread_pool_thread_num = 48

# 远程扫描线程池 的最大线程数：远程扫描线程池用于除内表外的所有扫描任务的执行
# doris_max_remote_scanner_thread_pool_thread_num = 512

# 当使用 分区哈希表 进行聚合和 join 计算时，是否进行 哈希桶 的预取
# enable_prefetch = true

# 当使用分区哈希表时发生 Hash 冲突时，是否采用平方探测法来解决 Hash 冲突：false，选用线性探测发来解决
# enable_quadratic_probing = true

# 交换节点缓存队列的大小（B）：Sender 端发送的数据量大于值后，后续发送的数据将阻塞直到缓存腾出可写入的空间
# exchg_node_buffer_size_bytes = 10485760


# 用于限制一个查询请求中，针对单个列，能够下推到存储引擎的最大条件数量
# max_pushdown_conditions_per_column = 1024

# OlapTableSink 发送批处理数据的最大并行度
# max_send_batch_parallelism_per_job = 5

# 每个 OlapScanner 读取的最大数据量
# doris_scan_range_max_mb = 1024
    
# ======================================================= 压缩 ======================================================= #
# 关闭自动执行压缩任务
# disable_auto_compaction = false

# 是否开启列式压缩
# enable_vertical_compaction = true

# 在列式压缩中，组成一个合并组的列个数
# vertical_compaction_num_columns_per_group = 5

# 在列式压缩中，行源缓冲器 能使用的最大内存（MB）
# vertical_compaction_max_row_source_memory_mb = 200

# 在列式压缩中，输出的分片文件最大值（MB）
# vertical_compaction_max_segment_size = 268435456

# 是否开启有序数据的压缩
# enable_ordered_data_compaction = true

# 在有序数据压缩中，满足要求的最小分片大小（MB）
# ordered_data_compaction_min_segment_size = 10485760

# 基础压缩线程池中线程数量的最大值
# max_base_compaction_threads = 4

# 生成压缩作业的最小间隔时间（ms）
# generate_compaction_tasks_interval_ms = 10 

# 基础压缩触发条件：累计文件数目要达到限制之后会触发基础压缩
# base_compaction_min_rowset_num = 5

# 基础压缩触发条件：累计文件大小达到文件的比例（30%）
# base_compaction_min_data_ratio = 0.3

# 被所有的压缩任务所能持有的 许可 上限，用来限制压缩占用的内存
total_permits_for_compaction_score = 50000

# 累计压缩的输出 rowset 总磁盘大小超过了此值，该 rowset 将用于基础压缩（MB）
# compaction_promotion_size_mbytes = 1024



# 累计压缩的输出 rowset 总磁盘大小超过基础版本 rowset 的配置比例时，该 rowset 将用于基础压缩：不要高于 0.1，不要低于 0.02
# compaction_promotion_ratio = 0.05

# 累计压缩的输出 rowset 总磁盘大小低于此值，该 rowset 将不进行基础压缩，仍然处于累计压缩流程中（MB）
# compaction_promotion_min_size_mbytes = 64

# 累计压缩进行合并时，选出的要进行合并的 rowset 的总磁盘大小大于此值时，才按级别策略划分合并，小于这个配置时，直接执行合并（MB）
# compaction_min_size_mbytes = 64

# 标识 BE 默认选择的存储格式，：ALPHA，BETA
# default_rowset_type = BETA

# 累计压缩策略：最小增量文件的数量
# cumulative_compaction_min_deltas = 5

# 累计压缩策略：最大增量文件的数量
# cumulative_compaction_max_deltas = 1000

# 打印基础压缩的 追溯 信息的阈值（s）
# base_compaction_trace_threshold = 10

# 打印累计压缩的 追溯 信息的阈值（s）：与 base_compaction_trace_threshold 类似
# cumulative_compaction_trace_threshold = 2

# 每个磁盘（HDD）可以并发执行的压缩任务数量
compaction_task_num_per_disk = 8

# 每个高速磁盘（SSD）可以并发执行的压缩任务数量
# compaction_task_num_per_fast_disk = 8

# 压缩任务的生产者每次连续生产多少轮累计压缩任务后生产一轮基础压缩
# cumulative_compaction_rounds_for_each_base_compaction_round = 9

# 配置 累计压缩 阶段的合并策略：size_based，ordinary 策略的优化版本，仅当 rowset 的磁盘体积在相同数量级时才进行版本合并
# cumulative_compaction_policy = size_based

# 累计压缩线程池中线程数量的最大值
# max_cumu_compaction_threads = 10

# 在导入时进行分片压缩来减少分片数量，以避免出现写入时错误
# enable_segcompaction = true

# 当分片数量超过此阈值时触发 分片压缩
# segcompaction_batch_size = 10

# 当分片的行数超过此大小时，则会在分片压缩时被 压缩，否则跳过
# segcompaction_candidate_max_rows = 1048576

# 单个分片压缩任务中的最大原始分片数量
# segcompaction_batch_size = 10

# 分片压缩任务中允许的单个原始分片行数，过大的分片将被跳过
# segcompaction_candidate_max_rows = 1048576

# 分片压缩任务中允许的单个原始分片大小（B），过大的分片将被跳过
# segcompaction_candidate_max_bytes = 104857600

# 单个分片压缩任务中允许的原始分片总行数
# segcompaction_task_max_rows = 1572864

# 单个分片压缩任务中允许的原始分片总大小（B）
# segcompaction_task_max_bytes = 157286400

# 分片压缩 线程池大小
# segcompaction_num_threads = 5

# 关闭压缩的追踪日志：如果为 true，累积压缩卓总阈值 和 基础压缩卓总阈值将不起作用，并且 trace 日志将关闭
# disable_compaction_trace_log = true

# 选取 rowset 去合并的时间间隔（s）
# pick_rowset_to_compact_interval_sec = 86400

# 单个副本压缩线程池中线程数量的最大值
# max_single_replica_compaction_threads = 10

# 更新 每个副本信息 的最小间隔时间（s）
# update_replica_infos_interval_seconds = 60
    
# ======================================================= 导入 ======================================================= #
# 是否开启 stream load 操作记录
# enable_stream_load_record = false

# mini load 数据文件将在此时间后被删除（h）
# load_data_reserve_hours = 4

# 导入线程数，用于处理 HIGH 优先级任务
# push_worker_count_high_priority = 3

# 导入线程数，用于处理NORMAL优先级任务
# push_worker_count_normal_priority = 3

# load 错误日志将在此时间后删除（h）
# load_error_log_reserve_hours = 48

# 单节点上所有的导入线程占据的内存上限比例（%）
# load_process_max_memory_limit_percent = 50

# soft limit 是指站单节点导入内存上限的比例，例如所有导入任务导入的内存上限是 20GB，则 soft limit 默认为该值的 50%，即 10GB（%）
# load_process_soft_mem_limit_percent = 50

# routine load 任务的线程池大小，这应该大于 FE 配置 max_concurrent_task_num_per_be
# routine_load_thread_pool_size = 10

# 单副本数据导入功能中，Master 副本和 Slave 副本之间通信的 RPC 超时时间
# slave_replica_writer_rpc_timeout_sec = 60

# 用于限制导入时，新产生的 rowset 中的分片数量，如果超过阈值，导入会失败并报错，过多的分片会导致压缩占用大量内存引发 OOM
# max_segment_num_per_rowset = 200

# 每个存储路径所分配的用于高优导入任务的刷写线程数量
# high_priority_flush_thread_num_per_store = 1

# routine load 所使用的数据消费者的缓存数量
# routine_load_consumer_pool_size = 10

# 一流多表使用该配置，表示攒多少条数据再进行规划，过小的值会导致规划频繁，多大的值会增加内存压力和导入延迟
# multi_table_batch_plan_threshold = 200

# 单副本数据导入功能中，Slave 副本通过 HTTP 从 Master 副本下载数据文件的工作线程数
# single_replica_load_download_num_workers = 64

# 当一个导入任务的超时时间小于这个阈值时，Doris 将认为他是一个高优任务，高优任务会使用独立的刷写线程池
# load_task_high_priority_threshold_second = 120

# load 作业中各个rpc 的最小超时时间
# min_load_rpc_timeout_ms = 20

# 如果依赖的 kafka 版本低于 0.10.0.0，该值应该被设置为 false
# kafka_api_version_request = true

# 如果依赖的 kafka 版本低于 0.10.0.0，当 kafka_api_version_request 值为 false 的时候，将使用回退版本 
# kafka_broker_version_fallback = 0.10.0

# 一个数据消费者组中的最大消费者数量，用于 routine load
# max_consumer_num_per_group = 3

# 用于限制数据格式为 csv 的一次 Stream load 导入中，允许的最大数据量（MB）：Stream Load 一般适用于导入几个 GB 以内的数据，不适合导入过大的数据
# streaming_load_max_mb = 10240

# 用于限制数据格式为 json 的一次 Stream load 导入中，允许的最大数据量（MB）
# streaming_load_json_max_mb =  100
    
# ======================================================= 线程 ======================================================= #
# 执行数据删除任务的线程数
# delete_worker_count = 3

# 用于清理事务的线程数
# clear_transaction_task_worker_count = 1

# 用于执行克隆任务的线程数
# clone_worker_count = 3

# BE 上 thrift server service 的执行线程数，代表可以用于执行 FE 请求的线程数
# be_service_threads = 64

# 下载线程数
# download_worker_count = 1

# 删除 tablet 的线程数
# drop_tablet_worker_count = 3

# 每个 store 用于刷新内存表的线程数
# flush_thread_num_per_store = 2

# 控制每个内核运行工作的线程数， 通常选择 2 倍或 3 倍的内核数量，这使核心保持忙碌而不会导致过度抖动
# num_threads_per_core = 3

# 每个磁盘的最大线程数也是每个磁盘的最大队列深度
# num_threads_per_disk = 0

# 每个 BE 节点上 Slave 副本同步 Master 副本数据的线程数，用于单副本数据导入功能
# number_slave_replica_download_threads = 64

# 生效版本的线程数
# publish_version_worker_count = 8

# 上传文件最大线程数
# upload_worker_count = 1

# webserver 默认工作线程数
# webserver_num_workers = 48

# SendBatch 线程池线程数目，决定了 SendBatch 线程池的大小
# send_batch_thread_pool_thread_num = 64

# SendBatch 线程池的队列长度
# send_batch_thread_pool_queue_size = 102400

# 制作快照的线程数
# make_snapshot_worker_count = 5

# 释放快照的线程数
# release_snapshot_worker_count = 5
    
# ======================================================= 内存 ======================================================= #
# 是否禁用内存缓存池
# disable_mem_pools = false

# 清理可能被缓冲池保存的页
# buffer_pool_clean_pages_limit = 50%

# 缓冲池之中最大的可分配内存
# buffer_pool_limit = 20%

# 块分配器的保留字节限制，通常被设置为 mem_limit 的百分比（B）：值必须是2的倍数，且必须大于0，如果大于物理内存，将被设置为物理内存大小
# chunk_reserved_bytes_limit = 20%

# 是否使用 linux 内存大页
# madvise_huge_pages = false

# 最大外部扫描缓存批次计数
# max_memory_sink_batch_count = 20

# 单个 schema change 任务允许占用的最大内存（GB）
# memory_limitation_per_thread_for_schema_change = 2

# 最大校对内存（GB）
# memory_max_alignment = 16

# 是否使用 mmap 分配内存
# mmap_buffers = false

# memtable 主动下刷时刷新内存统计的周期（ms）
# memtable_mem_tracker_refresh_interval_ms = 100

# 下载缓存时用于接收数据的缓冲的大小（B）
# download_cache_buffer_size = 10485760

# 如果一个 page 中的行数小于这个值就不会创建 zonemap，用来减少数据膨胀
# zone_map_row_num_threshold = 20

# 是否 Hook TCmalloc new/delete，目前在 Hook 中统计 thread local MemTracker
# enable_tcmalloc_hook = true

# 控制 tcmalloc 的回收：performance，内存使用超过 mem_limit 的 90% 时，doris 会释放 tcmalloc cache 中的内存；compact，内存使用超过 mem_limit 的 50% 时，会释放 tcmalloc cache 中的内存
# memory_mode = performance

# 系统 /proc/meminfo/MemAvailable 的最大低水位线（B）：实际低水位线 = min(1.6G，MemTotal * 10%)
# max_sys_mem_available_low_water_mark_bytes = 1717986918

# 单个 schema change 任务允许占用的最大内存（B）
# memory_limitation_per_thread_for_schema_change_bytes = 2147483648

# TCMalloc Hook consume/release MemTracker 时的最小长度（B）：小于该值的 consume size 会持续累加，避免频繁调用 MemTracker 的 consume/release
# mem_tracker_consume_min_size_bytes = 1048576

# 文件句柄缓存清理的间隔，用于清理长期不用的文件句柄，同时也是分片缓存的清理间隔时间（s）
# cache_clean_interval = 1800

# 最小读取缓冲区大小（B）
# min_buffer_size = 1024

# 刷写前缓冲区的大小（B）：导入数据在 BE 上会先写入到一个内存块，当这个内存块达到阈值后才会写回磁盘
# write_buffer_size = 104857600

# 读取 hdfs 或者对象存储上的文件时，使用的缓存大小（MB）
# remote_storage_read_buffer_mb = 16MB

# 分片缓存的分片最大数量
# segment_cache_capacity = 1000000

# 缓存文件的类型：whole_file_cache，将分片文件整个下载；sub_file_cache，将分片文件按大小切分成多个文件；""，则不缓存文件
# file_cache_type = ""

# 缓存文件的保存时间（s）
# file_cache_alive_time_sec = 604800

# 缓存占用磁盘大小（B）：超过设置值，会删除最久未访问的缓存，为 0 则不限制大小
# file_cache_max_size_per_disk = 0

# 缓存文件使用 sub_file_cache 时，切分文件的最大大小（B）
# max_sub_cache_file_size = 104857600

# 下载缓存线程池线程数目
# download_cache_thread_pool_thread_num = 48

# 下载缓存线程池线程队列大小
# download_cache_thread_pool_queue_size = 102400

# 缓存文件的清理间隔（s）
# generate_cache_cleaner_task_interval_sec = 43200

# 是否启用回收扫描数据线程检查
# path_gc_check = true

# 回收扫描数据线程检查时间间隔（s）
# path_gc_check_interval_second = 86400

# path_gc_check_step = 1000

# path_gc_check_step_interval_ms = 10

# path_scan_interval_second = 86400

# 用于上下文 gc 线程调度周期（min）
# scan_context_gc_interval_min = 5
    
# ======================================================= 存储 ======================================================= #
# 配置单个 RowBlock 之中包含多少行的数据
# default_num_rows_per_column_file_block = 1024

# 是否进行使用 页缓存 进行索引的缓存，该配置仅在 BETA 存储格式时生效
# disable_storage_page_cache = false

# 磁盘状态检查时间间隔（s）
# disk_stat_monitor_interval = 5

# 对于每个 io 缓冲区大小，IoMgr 将保留的最大缓冲区数从 1024B 到 8MB 的缓冲区，最多约为 2GB 的缓冲区
# max_free_io_buffers = 128

# 磁盘进行垃圾清理的最大间隔（s）
# max_garbage_sweep_interval = 3600

# 存储引擎允许存在损坏硬盘的百分比，损坏硬盘超过改比例后，BE 将会自动退出
# max_percentage_of_error_disk = 0

# 读取大小是发送到 os 的读取大小（B）：在延迟和整个过程之间进行权衡，试图让磁盘保持忙碌但不引入寻道， 对于 8 MB 读取，随机 io 和顺序 io 的性能相似
# read_size = 8388608

# 磁盘进行垃圾清理的最小间隔（s）
# min_garbage_sweep_interval = 180

# pprof profile 保存目录
# pprof_profile_dir = ${DORIS_HOME}/be/log

# 用于保存 SmallFileMgr 下载的文件的目录
# small_file_dir = ${DORIS_HOME}/be/lib/small_file/

# udf 函数目录
# user_function_dir = ${DORIS_HOME}/be/lib/udf

# 数据目录应该剩下的最小存储空间（B）
# storage_flood_stage_left_capacity_bytes = 1073741824

# 限制了数据目录的磁盘容量的最大使用（%）
# storage_flood_stage_usage_percent = 90

# 要克隆的线程数
# storage_medium_migrate_count = 1

# 缓存存储页大小
# storage_page_cache_limit = 20%

# 页缓存的分片大小，值为 2^n，设置为接近 BE CPU 核数的值
# storage_page_cache_shard_size = 16

# 索引页缓存占总页面缓存的百分比，取值为[0，100]
# index_page_cache_percentage = 10

# 用来检查不兼容的旧版本格式时是否使用严格的验证方式：当含有旧版本的 hdr 格式时，使用严谨的方式时，程序会打出 fatal log 并且退出运行；否则，程序仅打印 warn log
# storage_strict_check_incompatible_old_format =  true

# 存储引擎是否开 sync 保留到磁盘上
# sync_tablet_meta = false

# 存储引擎保留的未生效数据的最大时长（s）
# pending_data_expire_time_sec = 1800

# 用来决定当删除过期的合并过的rowset后无法构成一致的版本路径时，是否仍要删除
# ignore_rowset_stale_unconsistent_delete = false

# BE 创建 tablet 的工作线程数
# create_tablet_worker_count = 3

# 计算 tablet 的校验和的工作线程数
# check_consistency_worker_count = 1

# 限制单个 tablet 最大版本的数量：用于防止导入过于频繁，或压缩 不及时导致的大量 version 堆积问题，当超过限制后，导入任务将被拒绝
# max_tablet_version_num = 5000

# tablet 写线程数
# number_tablet_writer_threads = 16

# tablet_map_lock 分片大小，值为 2^n
# tablet_map_shard_size = 4

# Tablet 元数据检查点线程轮询的时间间隔（s）
# tablet_meta_checkpoint_min_interval_secs = 600

# Tablet 元数据检查点的最小 Rowset 数目
# tablet_meta_checkpoint_min_new_rowsets_num = 10

# tablet 状态缓存的更新间隔
# tablet_stat_cache_update_interval_second = 300

# 用来表示清理合并版本的过期时间
# tablet_rowset_stale_sweep_time_sec = 1800

# 在远程 BE 中打开 tablet writer的 rpc 超时，操作时间短，可设置短超时时间
# tablet_writer_open_rpc_timeout_sec = 60

# 写入时可忽略 brpc 的错误
# tablet_writer_ignore_eovercrowded = false

# TabletsChannel 的存活时间，如果此时通道没有收到任何数据，通道将被删除
# streaming_load_rpc_max_alive_time_sec = 1200

# 进行 schema change 的线程数
# alter_tablet_worker_count = 3

# 进行 index change 的线程数
# alter_index_worker_count = 3

# 用来决定在有 tablet 加载失败的情况下是否忽略错误，继续启动 be
# ignore_load_tablet_failure = false

# 代理向 FE 报告磁盘状态的间隔时间（s）
# report_disk_state_interval_seconds = 60 

# 结果缓冲区取消时间
# result_buffer_cancelled_interval_time = 300

# 快照文件清理的间隔（s）
# snapshot_expire_time_sec = 172800

# 序列化 RowBatch 时是否使用 Snappy 压缩算法进行数据压缩
# compress_rowbatches = true

# BE 使用 JVM 堆内存的最大值，即 JVM 的 -Xmx 参数
# jvm_max_heap_size = 1024M
    
# ======================================================= 日志 ======================================================= #
# BE 日志数据的存储目录
sys_log_dir = ${DORIS_HOME}/be/log

# 日志级别：INFO < WARNING < ERROR < FATAL
sys_log_level = INFO

# 日志拆分的大小，每 1G 拆分一个日志文件
# sys_log_roll_mode = SIZE-MB-1024

# 日志文件保留的数目
# sys_log_roll_num = 10

# 日志显示的级别，用于控制代码中 VLOG 开头的日志输出
# sys_log_verbose_level = 10

# 日志打印的模块，写 olap 就只打印 olap 模块下的日志
# sys_log_verbose_modules = *

# AWS SDK 的日志级别：Off = 0，Fatal = 1，Error = 2，Warn = 3，Info = 4，Debug = 5，Trace = 6
# aws_log_level = 3

# 日志刷盘的策略，默认保持在内存中
# log_buffer_level = -1
    
# ======================================================= 其他 ======================================================= #
# 代理向 FE 报告 olap 表的间隔时间（s）
# report_tablet_interval_seconds = 60

# 代理向 FE 报告任务签名的间隔时间（s）
# report_task_interval_seconds = 10

# 更新速率计数器和采样计数器的周期（ms）
# periodic_counter_update_period_ms = 500

# 如果设置为 true，metric calculator 将运行，收集 BE 相关指标信息，如果设置成 false 将不运行
# enable_metric_calculator = true

# 用户控制打开和关闭系统指标
# enable_system_metrics = true

# 用于向前兼容，稍后将被删除
# enable_token_check = true

# txn 管理器中每个 txn_partition_map 的最大 txns 数，这是一种自我保护，以避免在管理器中保存过多的 txns
# max_runnings_transactions_per_txn_map = 2000

# 最大下载速度限制（KB/s）
# max_download_speed_kbps = 50000

# 下载时间限制（s）
# download_low_speed_time = 300

# 下载最低限速（KB/s）
# download_low_speed_limit_kbps = 50

# 分配给 doris 的 cgroups
# doris_cgroups

# BlockingPriorityQueue 中剩余任务的优先级频率增加
# priority_queue_remaining_tasks_increased_frequency = 512

# 存放 jdbc driver 的默认目录
# jdbc_drivers_dir = ${DORIS_HOME}/be/jdbc_drivers

# 在动态表中是否解析多维数组，如果是 false 遇到多维数组则会报错
# enable_parse_multi_dimession_array = true

# 是否在导入 json 数据时用 simdjson 来解析
# enable_simdjson_reader = true

# 如果为 true，则当内存未超过 exec_mem_limit 时，查询内存将不受限制；当进程内存超过 exec_mem_limit 且大于 2GB 时，查询会被取消，如果为false，则在使用的内存超过 exec_mem_limit 时取消查询
# enable_query_memory_overcommit = true
    
# ====================================================== 自定义参数 ================================================== #
max_compaction_threads = 16

cumulative_size_based_promotion_size_mbytes = 2048

row_step_for_compaction_merge_log = 1

# 表明大小写不敏感
# lower_case_table_names = 1

capacity_used_percent_flood_stage = 98


# PPROF_TMPDIR=${DORIS_HOME}/be/tmp
